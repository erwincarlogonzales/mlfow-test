{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Region</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Literacy rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>15+</td>\n",
       "      <td>female</td>\n",
       "      <td>0.176121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>15+</td>\n",
       "      <td>male</td>\n",
       "      <td>0.454171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>15-24</td>\n",
       "      <td>female</td>\n",
       "      <td>0.321132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>15-24</td>\n",
       "      <td>male</td>\n",
       "      <td>0.618791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Central and Southern Asia</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2011</td>\n",
       "      <td>25-64</td>\n",
       "      <td>female</td>\n",
       "      <td>0.084128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Region      Country  Year    Age  Gender  Literacy rate\n",
       "0  Central and Southern Asia  Afghanistan  2011    15+  female       0.176121\n",
       "1  Central and Southern Asia  Afghanistan  2011    15+    male       0.454171\n",
       "2  Central and Southern Asia  Afghanistan  2011  15-24  female       0.321132\n",
       "3  Central and Southern Asia  Afghanistan  2011  15-24    male       0.618791\n",
       "4  Central and Southern Asia  Afghanistan  2011  25-64  female       0.084128"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    return df\n",
    "\n",
    "file_path = 'data/literacy_rates_clean.csv'\n",
    "df = load_data(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3303 entries, 0 to 3302\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Region         3303 non-null   object \n",
      " 1   Country        3303 non-null   object \n",
      " 2   Year           3303 non-null   int64  \n",
      " 3   Age            3303 non-null   object \n",
      " 4   Gender         3303 non-null   object \n",
      " 5   Literacy rate  3303 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(4)\n",
      "memory usage: 155.0+ KB\n",
      "None\n",
      "----------------------------------------\n",
      "Number of duplicates: 0\n",
      "\n",
      "Number of missing values: Region           0\n",
      "Country          0\n",
      "Year             0\n",
      "Age              0\n",
      "Gender           0\n",
      "Literacy rate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def eda(df):\n",
    "\n",
    "    duplicates = df.duplicated().sum()\n",
    "    missing_values = df.isnull().sum()\n",
    "    data_types = df.info()\n",
    "\n",
    "    print(data_types)\n",
    "    print('--' * 20)\n",
    "    print(f\"Number of duplicates: {duplicates}\")\n",
    "    print(f\"\\nNumber of missing values: {missing_values}\")\n",
    "    \n",
    "eda(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Determine the target variable\n",
    "y = df['Literacy rate']\n",
    "X = df.drop(columns='Literacy rate')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Select categorical and numerical columns\n",
    "num_cols = make_column_selector(dtype_include='number')\n",
    "cat_cols = make_column_selector(dtype_include='object')\n",
    "\n",
    "# Instantiate the transformers\n",
    "scaler = StandardScaler()\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "# Create preprocessing pipeline\n",
    "def preprocessing_pipeline():\n",
    "\n",
    "    # Create numeric and categorical pipelines\n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('scaler', scaler)\n",
    "    ])\n",
    "\n",
    "    cat_pipe = Pipeline([\n",
    "        ('encoder', encoder)\n",
    "    ])\n",
    "\n",
    "    # Create preprocessor\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numeric', num_pipe, num_cols),\n",
    "        ('categorical', cat_pipe, cat_cols)\n",
    "    ])\n",
    "\n",
    "    return preprocessor\n",
    "\n",
    "# Apply the preprocessing pipeline\n",
    "preprocessor = preprocessing_pipeline()\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|‚ñà‚ñã        | 7/42 [00:00<00:01, 27.17it/s]  File \"c:\\Users\\erwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\erwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\erwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1024, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\erwin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1493, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 42/42 [00:04<00:00,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor model failed to execute\n",
      "'super' object has no attribute '__sklearn_tags__'\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 190\n",
      "[LightGBM] [Info] Number of data points in the train set: 2642, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 0.816639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted R-Squared</th>\n",
       "      <th>R-Squared</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Time Taken</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LGBMRegressor</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HistGradientBoostingRegressor</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestRegressor</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BaggingRegressor</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
       "Model                                                                         \n",
       "LGBMRegressor                                0.87       0.87  0.08        0.10\n",
       "HistGradientBoostingRegressor                0.87       0.87  0.08        0.40\n",
       "RandomForestRegressor                        0.79       0.79  0.10        0.53\n",
       "BaggingRegressor                             0.75       0.76  0.11        0.08\n",
       "KNeighborsRegressor                          0.75       0.75  0.11        0.03"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Instantiate the model\n",
    "lazy_model = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n",
    "\n",
    "# Fit the model\n",
    "models, predictions = lazy_model.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Print the top 5 models\n",
    "top_5 = models.sort_values('Adjusted R-Squared', ascending=False).head()\n",
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Evaluate models\n",
    "def evaluate_models(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'Mean Squared Error: {mse:.2f}')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'R-Squared: {r2:.2f}')\n",
    "\n",
    "    return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.04\n",
      "Mean Squared Error: 0.00\n",
      "Root Mean Squared Error: 0.06\n",
      "R-Squared: 0.92\n",
      "Model: XGBRegressor\n",
      "----------------------------------------\n",
      "Mean Absolute Error: 0.04\n",
      "Mean Squared Error: 0.01\n",
      "Root Mean Squared Error: 0.08\n",
      "R-Squared: 0.88\n",
      "Model: RandomForestRegressor\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Run models\n",
    "models = [\n",
    "    XGBRegressor(),\n",
    "    RandomForestRegressor(random_state=42)\n",
    "]\n",
    "\n",
    "for model_name in models:\n",
    "    model_name.fit(X_train_transformed, y_train)\n",
    "    y_pred = model_name.predict(X_test_transformed)\n",
    "    evaluate_models(y_test, y_pred)\n",
    "\n",
    "    print(f'Model: {model_name.__class__.__name__}')   \n",
    "    print('--' * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=0289778a-278a-460b-b243-81dcf9f7b26f&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=2e8c64040ba09d450850a18844b2aa3db87b24a7ec841668bf99f4e35e7dfd24\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as erwincarlogonzales\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as erwincarlogonzales\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"erwincarlogonzales/mlflow-basics\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"erwincarlogonzales/mlflow-basics\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository erwincarlogonzales/mlflow-basics initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository erwincarlogonzales/mlflow-basics initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/01dd4db9f9664444976b43ab86f9165c', creation_time=1733667369822, experiment_id='0', last_update_time=1733667369822, lifecycle_stage='active', name='literacy-rate', tags={}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import dagshub\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize dagshub\n",
    "dagshub.init(\n",
    "    repo_owner=os.getenv('DAGSHUB_REPO_OWNER'),\n",
    "    repo_name=os.getenv('DAGSHUB_REPO_NAME'),\n",
    "    mlflow=True\n",
    ")\n",
    "\n",
    "# Set up MLflow tracking\n",
    "mlflow.set_experiment('literacy-rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train and track models\n",
    "# with mlflow.start_run(run_name='XGBRegressor'):\n",
    "    \n",
    "#     # Log parameters\n",
    "#     mlflow.log_param('test_size', 0.2)\n",
    "#     mlflow.log_param('random_state', 42)\n",
    "\n",
    "#     # Train model\n",
    "#     xgb_regressor = XGBRegressor()\n",
    "#     xgb_regressor.fit(X_train_transformed, y_train)\n",
    "\n",
    "#     # Make predictions and evaluate\n",
    "#     y_pred = xgb_regressor.predict(X_test_transformed)\n",
    "#     mae, mse, rmse, r2 = evaluate_models(y_test, y_pred)\n",
    "\n",
    "#     # Log metrics\n",
    "#     mlflow.log_metrics({\n",
    "#         'Mean Absolute Error': mae,\n",
    "#         'Mean Squared Error': mse,\n",
    "#         'Root Mean Squared Error': rmse,\n",
    "#         'R-Squared': r2\n",
    "#     })\n",
    "\n",
    "#     # Create signature for the model\n",
    "#     signature = mlflow.models.infer_signature(\n",
    "#         X_train_transformed,  # input example\n",
    "#         y_train              # output example\n",
    "#     )\n",
    "\n",
    "#     # Log the model with signature and input example\n",
    "#     mlflow.xgboost.log_model(\n",
    "#         xgb_regressor, \n",
    "#         \"model\",\n",
    "#         signature=signature,\n",
    "#         input_example=X_train_transformed[:5]  # First 5 rows as example\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with mlflow.start_run(run_name='RandomForestRegressor'):\n",
    "\n",
    "#     # Log parameters\n",
    "#     mlflow.log_param('test_size', 0.2)\n",
    "#     mlflow.log_param('random_state', 42)\n",
    "\n",
    "#     # Train model\n",
    "#     rf_regressor = RandomForestRegressor(random_state=42)\n",
    "#     rf_regressor.fit(X_train_transformed, y_train)\n",
    "\n",
    "#     # Make predictions\n",
    "#     y_pred = rf_regressor.predict(X_test_transformed)\n",
    "#     mae, mse, rmse, r2 = evaluate_models(y_test, y_pred)\n",
    "\n",
    "#     # Log metrics\n",
    "#     mlflow.log_metrics({\n",
    "#         'Mean Absolute Error': mae,\n",
    "#         'Mean Squared Error': mse,\n",
    "#         'Root Mean Squared Error': rmse,\n",
    "#         'R-Squared': r2\n",
    "#     })\n",
    "\n",
    "#     # Create signature for the model\n",
    "#     signature = mlflow.models.infer_signature(\n",
    "#         X_train_transformed,\n",
    "#         y_train\n",
    "#     )\n",
    "\n",
    "#     # Log the model with signature and input example\n",
    "#     mlflow.sklearn.log_model(\n",
    "#         rf_regressor, \n",
    "#         \"model\",\n",
    "#         signature=signature,\n",
    "#         input_example=X_train_transformed[:5]  # First 5 rows as example\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.04\n",
      "Mean Squared Error: 0.00\n",
      "Root Mean Squared Error: 0.06\n",
      "R-Squared: 0.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/12/28 04:57:57 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: C:\\Users\\erwin\\AppData\\Local\\Temp\\tmp8fllhzin\\model, flavor: xgboost). Fall back to return ['xgboost==2.1.3']. Set logging level to DEBUG to see the full traceback. \n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 1730.94it/s]\n",
      "2024/12/28 04:57:57 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      0.38363884943889986,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      1.1159898900584795,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      1.1159898900584795,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      1.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      1.482165410368269,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ],\n",
      "    [\n",
      "      -1.081063231800259,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      1.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: 'super' object has no attribute '__sklearn_tags__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run XGBRegressor at: https://dagshub.com/erwincarlogonzales/mlflow-basics.mlflow/#/experiments/0/runs/356612a471b347ec9f138fcfe6cbf756\n",
      "üß™ View experiment at: https://dagshub.com/erwincarlogonzales/mlflow-basics.mlflow/#/experiments/0\n",
      "Mean Absolute Error: 0.04\n",
      "Mean Squared Error: 0.01\n",
      "Root Mean Squared Error: 0.08\n",
      "R-Squared: 0.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 467.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run RandomForestRegressor at: https://dagshub.com/erwincarlogonzales/mlflow-basics.mlflow/#/experiments/0/runs/cc357a3dc68944e49de659f5c1e43c8c\n",
      "üß™ View experiment at: https://dagshub.com/erwincarlogonzales/mlflow-basics.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "# List of models and params\n",
    "models_config = [\n",
    "    {\n",
    "        'model_class': XGBRegressor,\n",
    "        'model_name': 'XGBRegressor',\n",
    "        'mlflow_module': mlflow.xgboost,\n",
    "        'params': {}  # Add XGBoost specific parameters here\n",
    "    },\n",
    "    {\n",
    "        'model_class': RandomForestRegressor,\n",
    "        'model_name': 'RandomForestRegressor',\n",
    "        'mlflow_module': mlflow.sklearn,\n",
    "        'params': {'random_state': 42}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Function to train and log a model\n",
    "def train_and_log_model(\n",
    "    model_class, \n",
    "    model_name, \n",
    "    X_train, \n",
    "    X_test, \n",
    "    y_train, \n",
    "    y_test, \n",
    "    params=None,\n",
    "    mlflow_module=None\n",
    "):\n",
    "    \n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Log common parameters\n",
    "        mlflow.log_param('test_size', 0.2)\n",
    "        mlflow.log_param('random_state', 42)\n",
    "        \n",
    "        # Initialize and train model\n",
    "        model = model_class(**(params or {}))\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions and evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        mae, mse, rmse, r2 = evaluate_models(y_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'Mean Absolute Error': mae,\n",
    "            'Mean Squared Error': mse,\n",
    "            'Root Mean Squared Error': rmse,\n",
    "            'R-Squared': r2\n",
    "        })\n",
    "        \n",
    "        # Create and log model with signature\n",
    "        signature = mlflow.models.infer_signature(X_train, y_train)\n",
    "        \n",
    "        mlflow_module.log_model(\n",
    "            model,\n",
    "            \"model\",\n",
    "            signature=signature,\n",
    "            input_example=X_train[:5]\n",
    "        )\n",
    "        \n",
    "        return model, y_pred\n",
    "\n",
    "# Train all models\n",
    "for config in models_config:\n",
    "    model, predictions = train_and_log_model(\n",
    "        model_class=config['model_class'],\n",
    "        model_name=config['model_name'],\n",
    "        X_train=X_train_transformed,\n",
    "        X_test=X_test_transformed,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        params=config['params'],\n",
    "        mlflow_module=config['mlflow_module']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# Model registry\n",
    "def register_model(run_id, model_name):\n",
    "    model_uri = f'runs:/{run_id}/model'\n",
    "\n",
    "    return mlflow.register_model(model_uri=model_uri, name=model_name)\n",
    "\n",
    "# Promote model\n",
    "def promote_challenger_to_production(model_name, prod_name):\n",
    "    client = MlflowClient()\n",
    "    current_model_uri = f\"models:/{model_name}@challenger\"\n",
    "    client.copy_model_version(src_model_uri=current_model_uri, dst_name=prod_name)\n",
    "\n",
    "# Retrieve production model\n",
    "def get_production_champion(prod_name):\n",
    "    prod_model_uri = f\"models:/{prod_name}@champion\"\n",
    "    return mlflow.xgboost.load_model(prod_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGBRegressor' already exists. Creating a new version of this model...\n",
      "2024/12/28 04:58:18 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: XGBRegressor, version 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registered model version: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '5' of model 'XGBRegressor'.\n"
     ]
    }
   ],
   "source": [
    "run_id = '26bbc91b56a542c38d5b5afe473601ff' # Get this from MLflow UI\n",
    "model_name = 'XGBRegressor'\n",
    "prod_name = 'literacy-rate-production'\n",
    "\n",
    "# Register model\n",
    "model_details = register_model(run_id, model_name)\n",
    "print(f'Registered model version: {model_details.version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'literacy-rate-production' already exists. Creating a new version of this model...\n",
      "Copied version '1' of model 'XGBRegressor' to version '5' of model 'literacy-rate-production'.\n"
     ]
    }
   ],
   "source": [
    "# Promote challenger to production => make sure to add challenger to the model alias\n",
    "promote_challenger_to_production(model_name, prod_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
